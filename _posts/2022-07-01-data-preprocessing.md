---
title: 資料前處理技術
tags: Data-Preprocessing
---

前言
-------------

> 資料前處理是指在進行資料探勘之前，為了讓資料更適合進行探勘的工作，對於資料所做的預處理動作。
>
> 資料前置處理通常花費整個專案約80%的時間，同時資料前處理也是對探勘品質影響最大的一個關鍵步驟。
>
> 資料前置處理的主要目的就是解決資料品質不良的問題，使得探勘結果的品質得以提升。
>
> 若未有好的資料前處理步驟，則會造成「Garbage in, garbage out」的狀況，沒有好的資料，就難以產生好的資料價值。

未經處理的資料通常會有哪些情況?
-------------
(一) 資料不完整 ( Data Incomplete )

(二) 資料雜訊 ( Noise Data )

(三) 資料不一致 ( Data Inconsistency )

(四) 資料重複 ( Data Redundancy )

### (一) 資料不完整 ( Data Incomplete )

資料不完整最常見的情況便是資料中的某些欄位屬性值有遺漏

例如：
表一

|CustomerId|Name|Sex|Height|Weight|Income|
| ---      |--- |---|---   |---   |---   |
|1         |James   |Male  |1.7m     |75kg     |55k/month     |
|2         |Mary   |Female  |160cm     |Nan     |Nan     |
|3         |Robert   |Male  |180cm     |80kg     |Nan     |
|4         |John   |Male  |245cm     |120kg     |65k/month     |
|5         |Patricia   |Female  |165cm     |Nan     |35k/month     |

以上表的情況顯示Nan的值就為遺漏值

### (二) 資料雜訊 ( Noise Data )

此問題可能的原因多半是**<font color=red>資料有誤</font>**或是**<font color=red>特例( Outlier )</font>**所造成。

例如：填寫資料表時，可能因為某種原因而填寫錯誤的資料。

但非所有雜訊皆由故意填錯而造成，而是資料本身屬於特例。

如表一所示，John的身高為245cm，但以台灣人的身高而言，通常介於161cm~192cm之間，在這種情況下，John的身高將被判定為雜訊。

資料有雜訊不僅可能導致探勘的結果不正確，也可能誤導後續的分析結果。

### (三) 資料不一致 ( Data Inconsistency )

產生資料不一致的原因通常為，資料由不同來源整合而得所產生。

以表一為例，James的身高單位為m。而在本表中，應該皆為cm，若**<font color=red>沒有經過適當的單位轉換</font>**，便會產生**<font color=red>完全不正確的探勘結果</font>**。


資料前處理說明
-------------
資料前處理主要包含**<font color=red>資料整合( Data Integration )</font>**、**<font color=red>資料清理( Data Cleaning )</font>**以及**<font color=red>資料轉換( Data Transformation )</font>** 。

### (一) 資料整合( Data Integration )

「資料整合」是指將多重來源的資料整合在一個貯存庫中，但因為資料都來自不同的資料源，會產生資料對不了、或是重複。因此資料整合最主要的目的便是解決多重資料來源的整合問題。

資料整合的主要工作有二
* 消除資料不一致
* 消除資料重複性

#### 資料不一致的情況

**<font color=red>數值不一致</font>**

例如：以表一為例，James的身高單位為m。而在本表中，應該皆為cm。這種數值單位不一致的現象，透過單位換算，使數值的計算單位統一，即可消除。

例如：同一位會員在A資料表中記錄的年齡是30歲，然而在B資料表中卻是25歲。因為無法判定究竟哪一個資料表是正確的，通常會採取的作法是將該屬性的資料刪除，以空值來取代，以消除內容不一致的情況。

**<font color=red>綱目不一致</font>**

通常是資料欄位名稱不一所造成。

例如：有的資料來源用「會員姓名」這個屬性名稱，而另一個資料來源卻用「顧客姓名」這個屬性名稱，雖然名稱並不相同，但實際所代表的意義卻是一樣的，可以透過屬性更名的動作來進行統一。

結語：

資料整合可以整併所有類型的資料 (結構化、非結構化、批次和串流…等)，有利於完成難易度不同的工作，從庫存資料庫的基本查詢，到複雜的預測分析都不成問題。

#### 資料重複性的情況

**<font color=red>數值重複</font>**

例如：整合中發現兩個表中皆有某一位會員的資料，則可刪除其中一筆記錄，以免造成資料重複。

**<font color=red>綱目重複</font>**

例如：資料經整合之後發現其中同時包含生日以及年齡這兩個屬性，因為年齡可以從生日推導出來，因此可以將年齡這個屬性刪掉以避免資料重複。


### (二) 資料清理( Data Cleaning )

資料清理的主要目的是確認資料的**<font color=red>正確性</font>**以及**<font color=red>完整性</font>**，才能進行進一步的操作。

**<font color=red>正確性</font>**

正確性主要試想達到以下目標，包含：屬性的有效值或有效範圍、參考完整性、資料的合理性驗證、數值的唯一性。

**<font color=red>完整性</font>**

完整性主要試想達到以下目標，包含：是否缺少探勘所需的屬性、是否只包含統計整合過的資訊，而缺少詳細的單筆資料。


而為了完成資料清理的目標，在過程中，也可能會遇到含有**<font color=red>遺漏值</font>**或是**<font color=red>雜訊</font>**的欄位。

此時，則有學者發展**<font color=red>遺漏值填補</font>**及**<font color=red>雜訊消除</font>**的技巧。

#### 資料遺缺的原因

* 資料建立時未輸入
* 設備故障
* 為了避免錯誤的資料影響分析

#### 資料遺缺的處理方法

1. 直接忽略法：刪除該列的內容 
2. 人工填補法：採用人工來填補遺缺的資料。
3. 自動填補法
     * 新增一類 “未知”
     * 以平均值、中位數填入
     * 以眾數填入
     * 填入固定值
     * 以統計方法填入
     * 以ML的預測結果填入

#### 雜訊產生的原因

* 資料收集儀器暫時故障
* 資料輸入時的疏忽
* 資料本來就存在特例

#### 如何去除雜訊?
* 偵測雜訊，並移除
* 使用資料平滑化技術將雜訊變得平緩，能夠有效降低對於探勘結果的影響

#### 如何偵測雜訊?
* 肉眼觀察
* 使用統計方法：大於或小於平均值百分之二十以上、平均值加減三倍標準差
* ML方法：使用DB Scan偵測離群值

#### 資料平滑化方法
如果擺在一起可能會使章節太長，再麻煩各位[移駕到此觀看唷](https://fugu-lin.github.io/2022/07/01/data-smoothing.html)


### (三) 資料轉換( Data Transformation )
資料轉換是為了讓資料的數值在分析時不容易產生誤判錯誤，主要目的是將資料內容轉換成更容易探勘或是探勘結果可信度更高的狀態。

一般來說，資料轉換工作包含：
* 資料統整化(Data Aggregation)
* 資料一般化(Data Generalization)
* 建立新屬性(Attribute Construction)

更進階的資料轉換包含：
* 資料正規化(Data Normalization)
* 資料模糊化(Fuzzy)

結語
-------------
若對資料進行資料前處理，將有利於讓資料探勘的結果更加正確。而雖然現今的DL( Deep Learninng )技術，都能夠在訓練的過程中抓住特徵值，但反過來說，若能配合在某個領域的背景知識(Domain Knowledge)，事前對資料進行處理與初步的篩選，無論對於訓練的過程或是準確度的提升，絕對會更加事半功倍。